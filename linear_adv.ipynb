{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fooling classifiers for image recognition\n",
    "\n",
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "DATADIR = '/Users/sravana/Research/data/cifar-10-batches-py'\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Loads the CIFAR-10 dataset from data/\"\"\"\n",
    "    trainXlist = []\n",
    "    trainylist = []\n",
    "    for i in range(1, 5):\n",
    "        with open(os.path.join(DATADIR, 'data_batch_'+str(i))) as f:\n",
    "            datadict = cPickle.load(f)\n",
    "            trainXlist.append(datadict['data'])\n",
    "            trainylist.append(np.array(datadict['labels']))\n",
    "    trainX = np.vstack(trainXlist)\n",
    "    trainy = np.hstack(trainylist)\n",
    "\n",
    "    # batch 5 is half dev and half test data\n",
    "    with open(os.path.join(DATADIR, 'data_batch_5')) as f:\n",
    "        datadict = cPickle.load(f)\n",
    "        devtestX = datadict['data']\n",
    "        devtesty = np.array(datadict['labels'])\n",
    "        \n",
    "    num_dev_test = devtesty.size\n",
    "    devX = devtestX[:num_dev_test/2, :]\n",
    "    devy = devtesty[:num_dev_test/2]\n",
    "    testX = devtestX[num_dev_test/2:, :]\n",
    "    testy = devtesty[num_dev_test/2:]\n",
    "    print 'Loaded data'\n",
    "    return trainX, trainy, devX, devy, testX, testy\n",
    "    \n",
    "trainX, trainy, devX, devy, testX, testy = load_data()\n",
    "with open(os.path.join(DATADIR, 'batches.meta')) as f:\n",
    "    label_names = cPickle.load(f)['label_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing a few images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def visualize(img_flat):\n",
    "    img_R = img_flat[0:1024].reshape((32, 32))\n",
    "    img_G = img_flat[1024:2048].reshape((32, 32))\n",
    "    img_B = img_flat[2048:3072].reshape((32, 32))\n",
    "    img = np.dstack((img_R, img_G, img_B))\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, vmin=0, vmax=255)\n",
    "    \n",
    "for i in range(10):\n",
    "    visualize(trainX[i])\n",
    "    print label_names[trainy[i]]\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's only keep birds and automobiles for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainXbin = trainX[(trainy<=2) & (trainy>0), :]\n",
    "trainybin = trainy[(trainy<=2) & (trainy>0)]\n",
    "trainybin-=1\n",
    "\n",
    "testXbin = testX[(testy<=2) & (testy>0), :]\n",
    "testybin = testy[(testy<=2) & (testy>0)]\n",
    "testybin-=1\n",
    "\n",
    "print 'Filtered images'\n",
    "print trainXbin.shape\n",
    "print trainybin.shape\n",
    "print testXbin.shape\n",
    "print testybin.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classification\n",
    "\n",
    "### Train a linear classifier (logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "model = SGDClassifier(loss='hinge', alpha=0.001)\n",
    "model.fit(trainXbin, trainybin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "predy = model.predict(testXbin)\n",
    "print 'Accuracy:', 1-norm(predy-testybin, 0)/float(predy.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize some classified images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    visualize(testXbin[i])\n",
    "    print label_names[testybin[i]+1], label_names[predy[i]+1], testybin[i]==predy[i]\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fool the classifier \n",
    "\n",
    "The gradient of the loss with respect to the data for a linear classifer, ignoring the softmax activation function, is `-w`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = model.coef_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fool the classifier by doing gradient descent on the image: subtract `-w` (i.e., add `w`) to the image, scaled by a learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eta = 1e-2\n",
    "def fool(img_flat, w):\n",
    "    return (img_flat + w*eta).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    if predy[i]==testybin[i]:\n",
    "        if testybin[i]==0:\n",
    "            tmp = fool(testXbin[i], w)  # target = bird\n",
    "        else:\n",
    "            tmp = fool(testXbin[i], -w)  # target = automobile\n",
    "        #print norm(testXbin[0]-tmp, 0)\n",
    "        visualize(1-tmp)\n",
    "        print label_names[predy[i]+1], label_names[model.predict(tmp.reshape(1, -1))+1]\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "What happens if the classifier we want to fool is a neural network instead of a linear classifier? Then we simply do backpropagation to compute the gradient of the loss with respect to the image. The computations are a small extension from the ones we did to get the gradients of the weight and bias vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
